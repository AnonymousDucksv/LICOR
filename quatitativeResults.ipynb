{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity metric\n",
    "How sparse are the relevance maps is measured by using the saliency metric proposed in https://arxiv.org/pdf/2201.13291.pdf:\n",
    "\n",
    "$$\\textrm{r'} = \\frac{r -r_{\\textrm{min}}}{r_{\\textrm{min}} - r_{\\textrm{max}}} \\quad \\textrm{Sparsity} = \\frac{1}{r'_{\\textrm{mean}}}$$   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 07:49:34.704212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-21 07:49:35.814901: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-06-21 07:49:35.815389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-06-21 07:49:35.849839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 07:49:35.850323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.815GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2023-06-21 07:49:35.850345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-21 07:49:35.851719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-21 07:49:35.851755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-06-21 07:49:35.852983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-21 07:49:35.853188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-21 07:49:35.854417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-21 07:49:35.855082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-21 07:49:35.857686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-21 07:49:35.857818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 07:49:35.858363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 07:49:35.858803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-06-21 07:49:35.859359: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-21 07:49:35.859717: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-06-21 07:49:35.859812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 07:49:35.860288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.815GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2023-06-21 07:49:35.860313: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-21 07:49:35.860330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-21 07:49:35.860344: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-06-21 07:49:35.860357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-21 07:49:35.860371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-21 07:49:35.860385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-21 07:49:35.860398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-21 07:49:35.860410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-21 07:49:35.860473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 07:49:35.860972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 07:49:35.861409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-06-21 07:49:35.861443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-21 07:49:36.224045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-06-21 07:49:36.224073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-06-21 07:49:36.224077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-06-21 07:49:36.224278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 07:49:36.224661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 07:49:36.225021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-21 07:49:36.225352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7253 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2023-06-21 07:49:36.336386: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-06-21 07:49:36.336871: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3593390000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 72, 1, 5)]        0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 72, 1, 16)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 36, 1, 16)         0         \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 36, 1, 32)         1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 18, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "ConvOutput (Conv2D)          (None, 18, 1, 64)         6208      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,097\n",
      "Trainable params: 8,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 07:49:36.644021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-21 07:49:36.767983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-21 07:49:37.356468: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2023-06-21 07:49:37.399388: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 6s 9ms/step - loss: 0.5025 - auc: 0.8324 - val_loss: 0.0084 - val_auc: 1.0000\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0050 - auc: 1.0000 - val_loss: 0.0014 - val_auc: 1.0000\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0011 - auc: 1.0000 - val_loss: 5.2448e-04 - val_auc: 1.0000\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 4.2412e-04 - auc: 1.0000 - val_loss: 2.7578e-04 - val_auc: 1.0000\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 2.2647e-04 - auc: 1.0000 - val_loss: 1.7104e-04 - val_auc: 1.0000\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 1.3910e-04 - auc: 1.0000 - val_loss: 1.1809e-04 - val_auc: 1.0000\n",
      "63/63 - 0s - loss: 0.0084 - auc: 1.0000\n",
      "Test AUC score helix_1_start: 1.0\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 72, 1, 5)]        0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 72, 1, 16)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 1, 16)         0         \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 36, 1, 32)         1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "ConvOutput (Conv2D)          (None, 18, 1, 64)         6208      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,097\n",
      "Trainable params: 8,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4477 - auc_1: 0.9350 - val_loss: 0.0030 - val_auc_1: 1.0000\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0025 - auc_1: 1.0000 - val_loss: 8.4404e-04 - val_auc_1: 1.0000\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 5.9323e-04 - auc_1: 1.0000 - val_loss: 3.3105e-04 - val_auc_1: 1.0000\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 2.6601e-04 - auc_1: 1.0000 - val_loss: 1.5819e-04 - val_auc_1: 1.0000\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 1.8672e-04 - auc_1: 1.0000 - val_loss: 9.4853e-05 - val_auc_1: 1.0000\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 1.0147e-04 - auc_1: 1.0000 - val_loss: 6.7599e-05 - val_auc_1: 1.0000\n",
      "63/63 - 0s - loss: 0.0030 - auc_1: 1.0000\n",
      "Test AUC score helix_matching_random_amp_feat_time_no_phase: 1.0\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 72, 1, 5)]        0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 72, 1, 16)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 36, 1, 16)         0         \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 36, 1, 32)         1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 18, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "ConvOutput (Conv2D)          (None, 18, 1, 64)         6208      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,097\n",
      "Trainable params: 8,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6931 - auc_2: 0.5164 - val_loss: 0.6836 - val_auc_2: 0.6335\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6772 - auc_2: 0.6124 - val_loss: 0.6439 - val_auc_2: 0.7326\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6200 - auc_2: 0.7233 - val_loss: 0.6430 - val_auc_2: 0.8435\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5182 - auc_2: 0.8407 - val_loss: 0.4546 - val_auc_2: 0.9331\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3860 - auc_2: 0.9191 - val_loss: 0.3764 - val_auc_2: 0.9540\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3116 - auc_2: 0.9486 - val_loss: 0.2663 - val_auc_2: 0.9646\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2516 - auc_2: 0.9655 - val_loss: 0.2862 - val_auc_2: 0.9700\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2166 - auc_2: 0.9747 - val_loss: 0.5586 - val_auc_2: 0.9708\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2373 - auc_2: 0.9661 - val_loss: 0.2285 - val_auc_2: 0.9764\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1810 - auc_2: 0.9820 - val_loss: 0.1798 - val_auc_2: 0.9819\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1801 - auc_2: 0.9795 - val_loss: 0.1758 - val_auc_2: 0.9839\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1593 - auc_2: 0.9851 - val_loss: 0.1632 - val_auc_2: 0.9828\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1433 - auc_2: 0.9863 - val_loss: 0.1513 - val_auc_2: 0.9859\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1457 - auc_2: 0.9860 - val_loss: 0.1622 - val_auc_2: 0.9859\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1433 - auc_2: 0.9867 - val_loss: 0.1405 - val_auc_2: 0.9887\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1352 - auc_2: 0.9866 - val_loss: 0.1236 - val_auc_2: 0.9893\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1117 - auc_2: 0.9918 - val_loss: 0.1364 - val_auc_2: 0.9905\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1328 - auc_2: 0.9858 - val_loss: 0.1453 - val_auc_2: 0.9904\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1209 - auc_2: 0.9885 - val_loss: 0.1107 - val_auc_2: 0.9907\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1122 - auc_2: 0.9918 - val_loss: 0.1040 - val_auc_2: 0.9915\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0904 - auc_2: 0.9944 - val_loss: 0.1017 - val_auc_2: 0.9923\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0821 - auc_2: 0.9946 - val_loss: 0.2396 - val_auc_2: 0.9907\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0966 - auc_2: 0.9936 - val_loss: 0.0922 - val_auc_2: 0.9929\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0838 - auc_2: 0.9943 - val_loss: 0.0906 - val_auc_2: 0.9937\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0697 - auc_2: 0.9959 - val_loss: 0.1365 - val_auc_2: 0.9926\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0912 - auc_2: 0.9939 - val_loss: 0.1315 - val_auc_2: 0.9948\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0854 - auc_2: 0.9940 - val_loss: 0.1778 - val_auc_2: 0.9931\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0946 - auc_2: 0.9926 - val_loss: 0.0740 - val_auc_2: 0.9949\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0695 - auc_2: 0.9964 - val_loss: 0.0699 - val_auc_2: 0.9956\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0693 - auc_2: 0.9957 - val_loss: 0.0883 - val_auc_2: 0.9942\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0635 - auc_2: 0.9968 - val_loss: 0.1443 - val_auc_2: 0.9956\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0614 - auc_2: 0.9970 - val_loss: 0.0818 - val_auc_2: 0.9962\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0619 - auc_2: 0.9965 - val_loss: 0.1098 - val_auc_2: 0.9952\n",
      "63/63 - 0s - loss: 0.0740 - auc_2: 0.9949\n",
      "Test AUC score helix_matching_random_amp_feat_time: 0.9948655366897583\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 510, 1, 3)]       0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 510, 1, 16)        4816      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 255, 1, 16)        0         \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 255, 1, 32)        51232     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 127, 1, 32)        0         \n",
      "_________________________________________________________________\n",
      "ConvOutput (Conv2D)          (None, 127, 1, 64)        204864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 260,977\n",
      "Trainable params: 260,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 7s 168ms/step - loss: 0.5690 - auc_3: 0.7451 - val_loss: 0.3446 - val_auc_3: 0.9773\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3177 - auc_3: 0.9587 - val_loss: 0.0765 - val_auc_3: 0.9926\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0676 - auc_3: 0.9967 - val_loss: 0.0356 - val_auc_3: 0.9996\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0344 - auc_3: 0.9991 - val_loss: 0.0235 - val_auc_3: 0.9997\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0078 - auc_3: 1.0000 - val_loss: 0.0068 - val_auc_3: 1.0000\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0362 - auc_3: 0.9986 - val_loss: 0.0451 - val_auc_3: 0.9996\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0583 - auc_3: 0.9988 - val_loss: 0.0640 - val_auc_3: 0.9935\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0563 - auc_3: 0.9978 - val_loss: 0.0254 - val_auc_3: 0.9997\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0197 - auc_3: 0.9998 - val_loss: 0.0068 - val_auc_3: 1.0000\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0095 - auc_3: 1.0000 - val_loss: 0.0027 - val_auc_3: 1.0000\n",
      "7/7 - 0s - loss: 0.0068 - auc_3: 1.0000\n",
      "Test AUC score blink_EEG: 1.0\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 72, 1, 5)]        0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 70, 1, 32)         480       \n",
      "_________________________________________________________________\n",
      "tf.nn.max_pool_with_argmax ( MaxPoolWithArgmax(output= 0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "Dense0 (Dense)               (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 14,031\n",
      "Trainable params: 14,031\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 4ms/step - loss: 0.3924 - auc_4: 0.8969 - val_loss: 0.0021 - val_auc_4: 1.0000\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0014 - auc_4: 1.0000 - val_loss: 4.1236e-04 - val_auc_4: 1.0000\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 3.2970e-04 - auc_4: 1.0000 - val_loss: 1.7493e-04 - val_auc_4: 1.0000\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 1.5706e-04 - auc_4: 1.0000 - val_loss: 9.2088e-05 - val_auc_4: 1.0000\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 7.6081e-05 - auc_4: 1.0000 - val_loss: 5.6890e-05 - val_auc_4: 1.0000\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 5.2314e-05 - auc_4: 1.0000 - val_loss: 3.8074e-05 - val_auc_4: 1.0000\n",
      "63/63 - 0s - loss: 0.0021 - auc_4: 1.0000\n",
      "Test AUC score helix_1_start: 1.0\n",
      "WARNING:tensorflow:5 out of the last 401 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56f00c3b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "from data_constructor import Dataset\n",
    "from model_constructor import Model\n",
    "from interpreter_constructor import Interpreter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_fraction = 0.8\n",
    "seed_int = 54321 # 54321\n",
    "\n",
    "subset = 'test'\n",
    "\n",
    "DATASET_LABELS = {'helix_1_start':\"Sine\",'helix_matching_random_amp_feat_time_no_phase':\"SineRandom\",'helix_matching_random_amp_feat_time':\"SineRandomPhase\",\"blink_EEG\":\"Blink EEG\"}\n",
    "MODELS_LABELS  = {'relu-mlp':'MLP LLM','conv-relu-mlp':'LICOR','CAM-conv':'CNN CAM'} \n",
    "\n",
    "AUC_METRICS = []\n",
    "N_splits = 5\n",
    "datasets = ['helix_1_start','helix_matching_random_amp_feat_time_no_phase','helix_matching_random_amp_feat_time','blink_EEG'] #'circles','moons','helix_1_start','helix_2_start','helix_1_random_time','helix_2_random_time','helix_random_feat_random_time','helix_matching_random_amp_feat_time', 'helix_matching_random_amp_feat_time_no_phase'\n",
    "models = ['CAM-conv','conv-relu-mlp','relu-mlp'] # 'relu-mlp', 'conv-relu-mlp', 'CAM-conv'\n",
    "SPARSITY = []\n",
    "for i, model_str in enumerate(models):\n",
    "    for ii, data_str in enumerate(datasets):\n",
    "        data = Dataset(data_str, train_fraction, seed_int)\n",
    "        model = Model(seed_int, data, model_str)\n",
    "        _,test_auc = model.train_model()\n",
    "        idx_list = range(199) \n",
    "        interpreter = Interpreter(data, model, idx_list, subset='test',use_bias=True)\n",
    "        SPARSITY.append([model_str,data_str,interpreter.getSparsity()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparsity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>blink_EEG</th>\n",
       "      <th>helix_1_start</th>\n",
       "      <th>helix_matching_random_amp_feat_time</th>\n",
       "      <th>helix_matching_random_amp_feat_time_no_phase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CAM-conv</th>\n",
       "      <td>0.015074</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.025126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv-relu-mlp</th>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.020674</td>\n",
       "      <td>0.008119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu-mlp</th>\n",
       "      <td>0.010944</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.023972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sparsity                                                    \\\n",
       "Dataset       blink_EEG helix_1_start helix_matching_random_amp_feat_time   \n",
       "Model                                                                       \n",
       "CAM-conv       0.015074      0.025126                            0.025126   \n",
       "conv-relu-mlp  0.002281      0.016425                            0.020674   \n",
       "relu-mlp       0.010944      0.021496                            0.023411   \n",
       "\n",
       "                                                            \n",
       "Dataset       helix_matching_random_amp_feat_time_no_phase  \n",
       "Model                                                       \n",
       "CAM-conv                                          0.025126  \n",
       "conv-relu-mlp                                     0.008119  \n",
       "relu-mlp                                          0.023972  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_sparsity = pd.DataFrame(SPARSITY, columns = [\"Model\", \"Dataset\",\"Sparsity\"])\n",
    "df_sparsity.pivot(index='Model',columns='Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsCF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
